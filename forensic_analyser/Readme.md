üïµÔ∏è AI IMAGE FORENSICS TOOLKIT: AMATEUR GUIDE

This toolkit provides two powerful, non-AI-based methods for digital image forensics, allowing users to detect the algorithmic fingerprints left by generative AI models like Midjourney, DALL-E, and Stable Diffusion.

The methodology combines Noise Residual Analysis (to check for natural sensor noise) and Frequency Domain Analysis (FFT) (to check for hidden grid patterns).

1. ‚öôÔ∏è Getting Started and Usage

This toolkit relies on two Python scripts to perform different types of artifact analysis.

1.1 Prerequisites

You must have Python 3 installed, along with the necessary scientific and image processing libraries.

pip install opencv-python numpy matplotlib


1.2 Execution Steps

Preparation: Rename the image you want to analyze to source.png and place it in the same directory as the Python scripts.

Primary Analysis: Run the main script for the 3-panel report:

python Photo_Auth1.py


This generates the CHECK_source.png file.

Alternative Check (Optional): Run the dedicated residual extractor for a higher resolution noise map:

python NoiseResidualExtractor1.py


This generates the RESIDUAL_source.png file.

2. üîç Interpreting the Technical Results

This section details how to read the output files generated by the analysis scripts.

2.1 Primary Output: CHECK_source.png (The 3-Panel Report)

The CHECK_source.png file provides three side-by-side plots for immediate comparative analysis: the Original Image, the Noise Residual, and the 2D FFT Magnitude Spectrum.

Panel A: Original Image

(Purpose: Context) The input image in grayscale. Use this purely for context and reference.

Panel B: Noise Residual (High-Pass Filter)

The goal of the noise residual panel is not to show a clean picture of the planes, but to reveal the underlying texture and consistency of the noise floor.

Image Source

Appearance in Residual Map

Interpretation

REAL Photo

Shows a uniform, random "fuzz" or grain across the entire picture.

The presence of genuine, randomized noise indicates the image was captured by a physical sensor.

AI Photo

Shows unnaturally smooth, solid black areas where noise should be, or structured/blotchy patterns.

AI models struggle to generate true random noise, often leaving these areas unnaturally clean (black), which is a major forensic giveaway.

Panel C: FFT Magnitude Spectrum

(Purpose: Algorithmic Fingerprint) This is the most crucial panel. It visualizes the frequency distribution of the image's noise, revealing periodic (repetitive) patterns left by the AI model's generation or upscaling process.

Characteristic of a Real Photo

Key Feature

Appearance in FFT Spectrum

Forensic Significance

Central Concentration

The brightest point is in the center, representing the dominant low-frequency content (the general structure and smooth areas of the image).

Standard for all images.

Smooth, Radial Decay

Looks like a central bright spot that smoothly fades outward to the dark edges. The pattern will be relatively random and chaotic in the outer regions.

This is characteristic of the natural, randomized noise and high-frequency details captured by a real camera sensor.

Absence of Strong Artifacts

We do not see sharp, symmetrical, geometric patterns.

Indicates the image lacks a hidden, repetitive grid.

Characteristic of an AI Photo

The tell-tale sign of a Synthetic (AI-generated) image in this type of analysis is the presence of Grid Artifacts (or "tells").

Key Feature

Appearance in FFT Spectrum

Forensic Significance

Periodic Artifacts

Look for bright, clear, and symmetrically paired spots (or crosses/grids) away from the center spot.

This is the AI model's "fingerprint" that the program has successfully isolated. AI models often leave these artifacts due to their internal upscaling or processing processes, which create a non-random, repetitive pattern.

2.2 Secondary Output: RESIDUAL_source.png (Alternative Residual Check)

This script, NoiseResidualExtractor1.py, is an ALTERNATIVE residual check that complements the residual panel found in the 3-panel report. It generates a higher-resolution, dedicated Residual Map.

Interpretation for RESIDUAL_source.png:

Look closely at the generated Residual Map image:

Real Photo: The map will show a uniform, random "fuzz" or grain across the whole picture. This is genuine sensor noise.

AI or Manipulation: The map will show unnaturally smooth, solid black areas where noise should be, or structured patterns instead of random grain. This indicates a lack of real noise.

3. üëÄ Manual Checks (Geometric & Logical Anomalies)

Even the most advanced AI models still fail at basic physics and detailed rendering. Always combine your technical analysis with these simple visual checks:

3.1 Geometric Consistency (Physics Fails)

Shadow and Lighting Inconsistency: Check the shadows cast by multiple objects. In a real scene, all shadows from a single light source must follow parallel lines that converge to a single point. AI often creates shadows that are inconsistent in direction or sharpness.

Reflection Discrepancy: Look closely at reflections in mirrors, glasses, or eyes. The reflection must geometrically match the object or light source. AI frequently generates blurred, distorted, or completely nonsensical reflections.

Eyes: Reflections (specular highlights) in both eyes should be identical in shape and color, as they are seeing the same light sources. AI often fails this test.

3.2 Detail and Context Anomalies

Hands and Digits: This is the most famous AI fail. Look for fingers that are fused, missing, bent at impossible angles, or have too many/too few joints.

Text and Symbols: AI struggles with coherent, legible text. Look at signs, books, labels, and tattoos for jumbled, gibberish, or inconsistent lettering.

Repetitive or Blurry Backgrounds: Areas the AI considers unimportant (e.g., distant trees, crowds, complex wallpapers) are often rendered with a repetitive, blurry, or "melting" texture lacking realistic detail.

Metadata: Before analysis, check the file's EXIF data. AI photos often have stripped metadata or generic entries like "Adobe Photoshop" rather than a real camera model (e.g., "Canon EOS R5").

A Note on Hidden Identifiers: Modern platforms and generative services (including some Google services) are beginning to incorporate digital watermarks or cryptographic signatures directly into the image data. While this toolkit focuses on revealing traditional algorithmic artifacts, always check for manufacturer-specific identifiers if they become publicly available.